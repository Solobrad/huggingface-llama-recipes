{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sina/.local/share/virtualenvs/huggingface-llama-recipes-RmwcKZVd/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, InferenceClient\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.docstore.document import Document\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration , you can change the model and other parameters\n",
    "CONFIG = {\n",
    "    \"model_name\": \"meta-llama/Llama-3.2-3B\",\n",
    "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"dataset\": \"Falah/story44kids_1_prompts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/sina/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Create a token Huggin Face and save it in your own .env.local file\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv('HF_TOKEN')\n",
    "login(token=token)\n",
    "\n",
    "client = InferenceClient(model=CONFIG[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "\n",
    "ds = load_dataset(CONFIG[\"dataset\"]) # You can replace this with any compatible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompts': ['Once upon a time, in a small village nestled on the outskirts of a mystical forest, there lived a poor but content farmer named Ethan. He had a modest cottage and a small plot of land where he grew vegetables to sustain himself. Despite the hardships that came his way, he always wore a smile and greeted everyone with warmth.', \"One sunny morning, as Ethan was tending to his crops, he heard a rustling in the bushes nearby. Curiosity piqued, he cautiously approached the sound and discovered a beautiful fox trapped in a hunter's snare. The fox looked at Ethan with pleading eyes, silently asking for help.\", 'Without a second thought, Ethan rushed over to free the fox. Using his trusted pocket knife, he carefully cut through the tangled mess until the fox was liberated. Grateful for being saved, the fox introduced herself as Fiona. She explained that she had gotten lost while exploring the depths of the mysterious forest.', \"Ethan, being a gentle soul, couldn't leave Fiona alone and lost in the forest. Determined to help her find her way back home, he offered his assistance. Armed with a small bag filled with supplies, the unlikely duo set out on an exciting adventure, navigating through the dense foliage of the lost forest.\", \"As they ventured deeper into the forest, Ethan and Fiona encountered a wide array of obstacles. They crossed treacherous ravines on rickety bridges, climbed towering trees to scout the surroundings, and even stumbled upon a hidden waterfall that enchanted them both. Through it all, they relied on each other's strength and resourcefulness.\"]}\n"
     ]
    }
   ],
   "source": [
    "# Print the first few examples\n",
    "\n",
    "print(ds['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the text in Document objects\n",
    "\n",
    "train_texts = [item[\"prompts\"] for item in ds['train']]\n",
    "documents = [Document(page_content=f\"Prompt: {text}\") for text in train_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split large documents into chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 10\n",
      "Chunk 1:\n",
      "Prompt: Once upon a time, in a small village nestled on the outskirts of a mystical forest, there lived a poor but content farmer named Ethan. He had a modest cottage and a small plot of land where he grew vegetables to sustain himself. Despite the hardships that came his way, he always wore a smile and greeted everyone with warmth.\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "Prompt: One sunny morning, as Ethan was tending to his crops, he heard a rustling in the bushes nearby. Curiosity piqued, he cautiously approached the sound and discovered a beautiful fox trapped in a hunter's snare. The fox looked at Ethan with pleading eyes, silently asking for help.\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "Prompt: Without a second thought, Ethan rushed over to free the fox. Using his trusted pocket knife, he carefully cut through the tangled mess until the fox was liberated. Grateful for being saved, the fox introduced herself as Fiona. She explained that she had gotten lost while exploring the depths of the mysterious forest.\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "Prompt: Ethan, being a gentle soul, couldn't leave Fiona alone and lost in the forest. Determined to help her find her way back home, he offered his assistance. Armed with a small bag filled with supplies, the unlikely duo set out on an exciting adventure, navigating through the dense foliage of the lost forest.\n",
      "--------------------------------------------------\n",
      "Chunk 5:\n",
      "Prompt: As they ventured deeper into the forest, Ethan and Fiona encountered a wide array of obstacles. They crossed treacherous ravines on rickety bridges, climbed towering trees to scout the surroundings, and even stumbled upon a hidden waterfall that enchanted them both. Through it all, they relied on each other's strength and resourcefulness.\n",
      "--------------------------------------------------\n",
      "Chunk 6:\n",
      "Prompt: Along their journey, they encountered a wise old owl named Oliver, who became their guide through the labyrinthine forest. Oliver shared stories of ancient creatures and hidden treasures, igniting the young fox's imagination and filling Ethan's heart with wonder. Together, they unraveled the secrets of the forest and forged an unbreakable bond.\n",
      "--------------------------------------------------\n",
      "Chunk 7:\n",
      "Prompt: Days turned into weeks, and as their friendship grew stronger, so did their determination to find Fiona's home. One misty morning, after a particularly challenging climb up a rocky hill, they reached a clearing that revealed a breathtaking view of Fiona's fox den in the distance.\n",
      "--------------------------------------------------\n",
      "Chunk 8:\n",
      "Prompt: Overwhelmed with joy, Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family.\n",
      "--------------------------------------------------\n",
      "Chunk 9:\n",
      "Prompt: Ethan returned to his humble cottage with a heart full of memories and a smile that shone brighter than ever before. He knew that the adventure he embarked upon with Fiona had transformed his perspective on life. The lost forest had gifted him with more than he could have ever imagined – courage, friendship, and a bond that transcended boundaries.\n",
      "--------------------------------------------------\n",
      "Chunk 10:\n",
      "Prompt: From that day forward, Ethan shared his remarkable tale with anyone who would listen. His story of kindness and bravery inspired the villagers, and the lost forest became more than just a mysterious place—it became a symbol of hope and wonder. And in the depths of the forest, where moss-covered trees whispered secrets, the memory of Ethan and Fiona's adventure lived on, forever etched in the hearts of all who heard their tale.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Verify the number of document chunks\n",
    "\n",
    "num_chunks = len(split_documents)\n",
    "print(f\"Number of document chunks: {num_chunks}\")\n",
    "\n",
    "# Print content of the chunks \n",
    "for i, doc in enumerate(split_documents):\n",
    "    print(f\"Chunk {i+1}:\\n{doc.page_content}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6q/mv1t578n5dd41214yd5lkclh0000gn/T/ipykernel_10980/3270508471.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=CONFIG[\"embedding_model\"])\n",
      "/Users/sina/.local/share/virtualenvs/huggingface-llama-recipes-RmwcKZVd/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/var/folders/6q/mv1t578n5dd41214yd5lkclh0000gn/T/ipykernel_10980/3270508471.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(embedding_function=embedding_model, persist_directory=\"./vector_base\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a328e838-c0ac-4113-9b0a-ee5e3ab04cd3',\n",
       " 'f1630594-2ae2-4329-a35b-d4aaccf88d9b',\n",
       " '1b5fd596-a71a-42d8-8280-83e8366ec041',\n",
       " 'fd301085-a6cf-41fe-ac81-02cc15ecd0a1',\n",
       " '7d50fcc7-371b-444b-85bc-2f5d5e5fe902',\n",
       " 'a4db7317-6f39-4da5-901e-a59445421915',\n",
       " '645a825d-8f9c-4929-b925-43bdefd1782d',\n",
       " '61f436d1-f1f2-46be-89e4-dbc7c5b4e292',\n",
       " 'db3f1f5d-1297-40f9-98b7-5e81a106c6c1',\n",
       " '278f0047-cef1-4c6b-9666-b6da6331b0f7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed the documents and initialize Chroma vector store\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=CONFIG[\"embedding_model\"])\n",
    "vector_store = Chroma(embedding_function=embedding_model, persist_directory=\"./vector_base\")\n",
    "vector_store.add_documents(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in the vector store: 140\n"
     ]
    }
   ],
   "source": [
    "# Check the number of documents stored in the vector store\n",
    "\n",
    "stored_embeddings = vector_store._collection.count()\n",
    "print(f\"Number of embeddings in the vector store: {stored_embeddings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the the number of documents you want to retrieve based on your query\n",
    "def retrieve_documents(query, num_docs=2): # num_docs specifies how many results to return\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=num_docs)\n",
    "    retrieved_texts = [doc.page_content for doc in retrieved_docs]\n",
    "    # Remove duplicate documents\n",
    "    retrieved_texts = list(dict.fromkeys(retrieved_texts))\n",
    "    print(\"Retrieved Documents:\", retrieved_texts)\n",
    "    return retrieved_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: ['Prompt: Overwhelmed with joy, Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family.']\n",
      "Retrieved documents:\n",
      "Document 1:\n",
      "Prompt: Overwhelmed with joy, Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family.\n",
      "==================================================\n",
      "\n",
      "Full prompt sent to the model:\n",
      "You are a helpful AI assistant. Answer ONLY the following question based on the context provided below. Do not generate or answer any other questions. If the answer cannot be found in the context, state 'I don't have enough information to answer that question.' Do not make up or infer any information that is not directly stated in the context. If you're unsure, say 'I'm not sure.' Provide a concise answer.\n",
      "\n",
      "Context:\n",
      "Prompt: Overwhelmed with joy, Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family.\n",
      "\n",
      "Question: Why did Fiona thank Ethan?\n",
      "Answer: \n",
      "==================================================\n",
      "\n",
      "Model response:\n",
      "1. Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. This indicates that Ethan provided her with emotional support during a difficult time, which is why she expressed gratitude towards him. 2. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family. This suggests that Fiona felt empowered and motivated after receiving Ethan's support, leading her to express gratitude and part ways with him on a positive note. 3. Fiona's gratitude towards Ethan was likely influenced by the emotional support he provided during a challenging period in her life. This support helped her regain confidence and find purpose, leading her to express her appreciation and bid farewell to him with a sense of fulfillment.<|end_of_text|>\n",
      "Full response: 1. Fiona thanked Ethan for his unwavering support and promised to always cherish their friendship. This indicates that Ethan provided her with emotional support during a difficult time, which is why she expressed gratitude towards him. 2. With newfound confidence and a sense of purpose, she bid farewell to Ethan, disappearing into the embrace of her family. This suggests that Fiona felt empowered and motivated after receiving Ethan's support, leading her to express gratitude and part ways with him on a positive note. 3. Fiona's gratitude towards Ethan was likely influenced by the emotional support he provided during a challenging period in her life. This support helped her regain confidence and find purpose, leading her to express her appreciation and bid farewell to him with a sense of fulfillment.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "class HFInferenceStreamer(StreamingStdOutCallbackHandler):\n",
    "    def __init__(self):\n",
    "        self.text = \"\"\n",
    "        \n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        self.text += token\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "def ask_query(query):\n",
    "    retrieved_docs = retrieve_documents(query)\n",
    "    print(\"Retrieved documents:\")\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        print(f\"Document {i+1}:\\n{doc}\\n{'='*50}\")\n",
    "    \n",
    "    combined_input = (\n",
    "        \"You are a helpful AI assistant. Answer ONLY the following question based on the context provided below. \"\n",
    "        \"Do not generate or answer any other questions. \"\n",
    "        \"If the answer cannot be found in the context, state 'I don't have enough information to answer that question.' \"\n",
    "        \"Do not make up or infer any information that is not directly stated in the context. \"\n",
    "        \"If you're unsure, say 'I'm not sure.' \"\n",
    "        \"Provide a concise answer.\\n\\n\"\n",
    "        f\"Context:\\n{' '.join(retrieved_docs)}\\n\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        \"Answer: \"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFull prompt sent to the model:\")\n",
    "    print(combined_input)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    streamer = HFInferenceStreamer()\n",
    "    response = client.text_generation(\n",
    "        combined_input, \n",
    "        max_new_tokens=200, \n",
    "        temperature=0.2,  # Low temperature for more focused responses\n",
    "        top_p=0.9,  # Added top_p to further control randomness\n",
    "        do_sample=False,  # Disable sampling for more deterministic output\n",
    "        stream=True\n",
    "    )\n",
    "    print(\"\\nModel response:\")\n",
    "    for token in response:\n",
    "        streamer.on_llm_new_token(token)\n",
    "    \n",
    "    return streamer.text.strip()\n",
    "\n",
    "# Usage\n",
    "query = \"Why did Fiona thank Ethan?\"\n",
    "response = ask_query(query)\n",
    "print(\"\\nFull response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_rag_env",
   "language": "python",
   "name": "llama_rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
