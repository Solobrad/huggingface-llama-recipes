{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First install the required libraries\n",
    "! pip install python-dotenv huggingface_hub sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, InferenceClient\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a05bed543d74a2fb891eb31a31c803c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a token Huggin Face and save it in your own .env.local file\n",
    "\n",
    "load_dotenv('.env.local')\n",
    "token = os.getenv('HF_TOKEN')\n",
    "login(token=token)\n",
    "\n",
    "client = InferenceClient(model=\"meta-llama/Llama-3.2-3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a dictionary with text snippets\n",
    "\n",
    "text_snippets = {\n",
    "    1: \"Fiona thanked Ethan for his unwavering support and promised to cherish their friendship.\",\n",
    "    2: \"As they ventured deeper into the forest, they encountered a wide array of obstacles.\",\n",
    "    3: \"Ethan and Fiona crossed treacherous ravines using rickety bridges, relying on each other's strength.\",\n",
    "    4: \"Overwhelmed with joy, Fiona thanked Ethan and disappeared into the embrace of her family.\",\n",
    "    5: \"Ethan returned to his cottage, heart full of memories and a smile brighter than ever before.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Embed all text snippets\n",
    "snippets_embedded = {key: model.encode(text) for key, text in text_snippets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function to retrieve the closest matching snippet using cosine similarity\n",
    "def retrieve_snippet(query, num_docs=2):\n",
    "    query_embedded = model.encode(query)\n",
    "    similarities = {key: util.pytorch_cos_sim(query_embedded, snippet_emb).item() \n",
    "                    for key, snippet_emb in snippets_embedded.items()}\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    closest_matches = sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:num_docs]\n",
    "    retrieved_texts = [text_snippets[key] for key, _ in closest_matches]\n",
    "    return retrieved_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate a new prompt with the retrieved text\n",
    "def ask_query(query):\n",
    "    retrieved_texts = retrieve_snippet(query)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Provide one Answer ONLY the following query based on the context provided below. \"\n",
    "                \"Do not generate or answer any other questions. \"\n",
    "                \"Do not make up or infer any information that is not directly stated in the context. \"\n",
    "                \"Provide a concise answer.\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "\n",
    "    combined_input = f\"{messages[0]['content']}\\n{messages[1]['content']}\\nContext:\\n\" + \"\\n\".join(retrieved_texts)\n",
    "    response = client.text_generation(combined_input, max_new_tokens=100, temperature=0.2)\n",
    "    \n",
    "    print(\"Query:\", query)\n",
    "    print(\"Context:\", \"\\n\".join(retrieved_texts))\n",
    "    print(\"Answer:\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Why did Fiona thank Ethan?\n",
      "Context: Fiona thanked Ethan for his unwavering support and promised to cherish their friendship.\n",
      "Overwhelmed with joy, Fiona thanked Ethan and disappeared into the embrace of her family.\n",
      "Answer:\n",
      " Ethan, on the other hand, was left with a sense of fulfillment and gratitude for his role in the success of the project.\n",
      "Fiona’s heartfelt gratitude was a testament to the strength of their friendship and the importance of teamwork. Ethan, in turn, felt a sense of accomplishment and pride in his contribution to the project.\n",
      "The context provided suggests that Fiona thanked Ethan for his unwavering support and promised to cherish their friendship. This implies that Ethan played a significant role in the success of the project\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Ask a question\n",
    "query = \"Why did Fiona thank Ethan?\"\n",
    "response = ask_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
